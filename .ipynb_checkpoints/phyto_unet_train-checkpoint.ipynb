{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 294115747506680000\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1312832237456540984\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#encoding:utf-9\n",
    "from model_v2 import  *\n",
    "from data import *\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "#import keras.backend.tensorflow_backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#config = tf.compat.v1.ConfigProto\n",
    "#config.gpu_options.allow_growth=True\n",
    "#sess = tf.Session(config=config)\n",
    "#K.set_session(sess)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# GPU testing\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    #path to images which are prepared to train a model\n",
    "    train_path = \"data/micro/train\"\n",
    "    image_folder = \"images\"\n",
    "    label_folder = \"labels\"\n",
    "    valid_path =  \"data/micro/validation\"\n",
    "    valid_image_folder =\"images\"\n",
    "    valid_label_folder = \"labels\"\n",
    "    log_filepath = './log'\n",
    "    flag_multi_class = True\n",
    "    num_classes = 3\n",
    "    batch_size = 2\n",
    "    dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
    "                         valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
    "                         flag_multi_class=flag_multi_class,\n",
    "                         num_classes=num_classes)\n",
    "\n",
    "    # train your own model\n",
    "    train_data = dp.trainGenerator(batch_size)\n",
    "    valid_data = dp.validLoad(batch_size)\n",
    "    test_data = dp.testGenerator()\n",
    "    model = unet(num_class=num_classes)\n",
    "\n",
    "    tb_cb = TensorBoard(log_dir=log_filepath)\n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint('./model/micro_model_v1.hdf5', monitor='val_loss',verbose=1,save_best_only=True)\n",
    "    history = model.fit_generator(train_data,\n",
    "                                  steps_per_epoch=128,epochs=100,\n",
    "                                  validation_steps=49,\n",
    "                                  validation_data=valid_data,\n",
    "                                  callbacks=[model_checkpoint,tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the loss and accuracy curve\n",
    "plt.figure(12, figsize=(6, 6), dpi=60)\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title('acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/home/server/Desktop/phyto_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_v2 import *\n",
    "from data import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "def image_normalized(file_path):\n",
    "    '''\n",
    "    tif，size:512*512，gray\n",
    "    :param dir_path: path to your images directory\n",
    "    :return:\n",
    "    '''\n",
    "    img = cv2.imread(file_path)\n",
    "    img_shape = img.shape\n",
    "    image_size = (img_shape[1],img_shape[0])\n",
    "    img_standard = cv2.resize(img, (512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "    img_new = img_standard\n",
    "    img_new = np.asarray([img_new / 255.])\n",
    "    return img_new,image_size\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #path to images which aring wating for predicting\n",
    "    test_path = \"data/phyto/test\"\n",
    "\n",
    "    # save the predict images\n",
    "    save_path = \"data/phyto/predicted_results\"\n",
    "\n",
    "    dp = data_preprocess(test_path=test_path,save_path=save_path,flag_multi_class=True,num_classes=3)\n",
    "\n",
    "    #load model\n",
    "    # model = load_model('./model/CamVid_model_v1.hdf5')\n",
    "\n",
    "    for name in os.listdir(test_path):\n",
    "        image_path = os.path.join(test_path,name)\n",
    "        x,img_size = image_normalized(image_path)\n",
    "        results = model.predict(x)\n",
    "        res2 = np.squeeze(results, axis=0)\n",
    "        plt.imshow(res2)\n",
    "        dp.saveResult([results[0]],img_size,name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is the same with the predict.py code. I retyped it here because during the experiments\n",
    "# I want to change the parameters without restarting the kernel\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "target_size = (512, 512)\n",
    "seed = np.random.randint(0,1e5)\n",
    "\n",
    "image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = ImageDataGenerator()\n",
    "\n",
    "test_image_generator = image_datagen.flow_from_directory('data/micro/validation/images', seed=seed, target_size=target_size, class_mode=None, batch_size =6)\n",
    "test_mask_generator = mask_datagen.flow_from_directory('data/micro/validation/labels', seed=seed, target_size=target_size, class_mode=None, batch_size = 6)\n",
    "\n",
    "def combine_generator(gen1, gen2, batch_list=6,training=True):\n",
    "  \n",
    "    while True:\n",
    "        image_batch, label_batch=next(gen1)[0], np.expand_dims(next(gen2)[0][:,:,0],axis=-1)\n",
    "        image_batch, label_batch=np.expand_dims(image_batch,axis=0),np.expand_dims(label_batch,axis=0)\n",
    "\n",
    "        for i in range(batch_list-1):\n",
    "            image_i,label_i = next(gen1)[0], np.expand_dims(next(gen2)[0][:,:,0],axis=-1)\n",
    "            \n",
    "            image_i, label_i=np.expand_dims(image_i,axis=0),np.expand_dims(label_i,axis=0)\n",
    "            image_batch=np.concatenate([image_batch,image_i],axis=0)\n",
    "            label_batch=np.concatenate([label_batch,label_i],axis=0)\n",
    "              \n",
    "        yield((image_batch,label_batch))\n",
    "\n",
    "test_generator = combine_generator(test_image_generator, test_mask_generator,training=True)\n",
    "\n",
    "\n",
    "def show_predictions_in_test(model_name, generator=None, num=3):\n",
    "    if generator ==None:\n",
    "        generator = test_generator\n",
    "    for i in range(num):\n",
    "        image, mask=next(generator)\n",
    "        sample_image, sample_mask= image[1], mask[1]\n",
    "        image = np.expand_dims(sample_image, axis=0)\n",
    "        pr_mask = model_name.predict(image)\n",
    "        pr_mask=np.expand_dims(pr_mask[0].argmax(axis=-1),axis=-1)\n",
    "        display([sample_image, sample_mask,pr_mask])\n",
    "        \n",
    "def display(display_list,title=['Input Image', 'True Mask', 'Predicted Mask']):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]),cmap='magma')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_predictions_in_test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
